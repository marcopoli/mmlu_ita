"Si lancia un dado a 6 facce 15 volte e i risultati sono: la faccia 1 esce 0 volte; la faccia 2: 1 volta; la faccia 3: 2 volte; la faccia 4: 3 volte; la faccia 5: 4 volte; la faccia 6: 5 volte. Basandosi su questi risultati, quale è la probabilità che esca la faccia 3 quando si utilizza la tecnica di Add-1 Smoothing?",2.0/15,1.0/7,3.0/16,1.0/5,B
Qual è la tecnica di data augmentation più comune per le immagini naturali?,Taglio casuale e ribaltamento orizzontale,Taglio casuale e ribaltamento verticale,Posterizzazione,Dithering,A
Stai revisionando le carte per la conferenza di apprendimento automatico più elegante del mondo e vedi presentazioni con le seguenti affermazioni. Quali di queste considereresti accettabili?,Il mio metodo raggiunge un errore di allenamento più basso di tutti i metodi precedenti!,Il mio metodo raggiunge un errore di test più basso di tutti i metodi precedenti! (Nota a piè di pagina: quando il parametro di regolarizzazione λ viene scelto per minimizzare l'errore di test.),Il mio metodo raggiunge un errore di test più basso di tutti i metodi precedenti! (Nota a piè di pagina: quando il parametro di regolarizzazione λ viene scelto per minimizzare l'errore di convalida incrociata.),Il mio metodo raggiunge un errore di convalida incrociata più basso di tutti i metodi precedenti! (Nota a piè di pagina: quando il parametro di regolarizzazione λ viene scelto per minimizzare l'errore di convalida incrociata.),C
"Per ottenere una stima di perdita 0/1 inferiore all'1% della perdita 0/1 reale (con probabilità del 95%), secondo l'ineguaglianza di Hoeffding, quanti esempi deve avere il set di test IID?",circa 10 esempi,circa 100 esempi,tra 100 e 500 esempi,più di 1000 esempi,D
"Tradizionalmente, durante l'apprendimento degli alberi decisionali con un'attributo di input a valore reale, consideriamo una divisione binaria in base al fatto che l'attributo sia sopra o sotto una determinata soglia. Pat suggerisce invece di avere una divisione multipla con un ramo per ciascun valore distinto dell'attributo. Dall'elenco sottostante scegli il singolo problema più grande della proposta di Pat:",È troppo costoso in termini di calcolo.,Probabilmente si otterrebbe un albero decisionale che ottiene un cattivo punteggio sul set di allenamento e su un set di test.,Probabilmente si otterrebbe un albero decisionale che ottiene un buon punteggio sul set di allenamento ma male su un set di test.,Probabilmente si otterrebbe un albero decisionale che ottiene un buon punteggio su un set di test ma male su un set di allenamento.,C
